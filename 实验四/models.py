# models.py - æ”¯æŒHF Tokençš„æ¨¡å‹åŠ è½½
# ======================================
import streamlit as st
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch


@st.cache_resource
def load_embedding_model(model_name):
    """åŠ è½½åµŒå…¥æ¨¡å‹"""
    st.write(f"æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}...")
    try:
        model = SentenceTransformer(model_name)
        st.success("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
    except Exception as e:
        st.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None


@st.cache_resource
def load_generation_model(model_name, hf_token=None):
    """åŠ è½½ç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æŒHF Tokené¿å…é™æµ"""
    st.write(f"æ­£åœ¨åŠ è½½ç”Ÿæˆæ¨¡å‹: {model_name}...")

    # è°ƒè¯•ä¿¡æ¯
    st.write(f"Tokenæ¥æ”¶çŠ¶æ€: {hf_token is not None}")
    if hf_token:
        st.write(f"Tokenå‰10ä½: {hf_token[:10]}...")

    try:
        # ä½¿ç”¨tokenå‚æ•°è¿›è¡Œèº«ä»½éªŒè¯
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True,
            token=hf_token
        )

        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            trust_remote_code=True,
            device_map="auto",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            token=hf_token
        )

        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        st.success("âœ… ç”Ÿæˆæ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸ")
        return model, tokenizer

    except Exception as e:
        st.error(f"âŒ ç”Ÿæˆæ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        # æ™ºèƒ½é”™è¯¯è¯Šæ–­
        if "429" in str(e):
            st.error("ğŸš¨ 429é™æµé”™è¯¯ï¼Tokenæœªç”Ÿæ•ˆæˆ–æ— æ•ˆ")
            st.info(f"è¯·æ£€æŸ¥Token: {hf_token[:10] if hf_token else 'None'}")
        elif "401" in str(e):
            st.error("ğŸš¨ 401æœªæˆæƒï¼Tokenæ— æ•ˆæˆ–æƒé™ä¸è¶³")
        elif "quota" in str(e).lower():
            st.warning("âš ï¸ å¯èƒ½æ˜¯HuggingFaceä¸‹è½½é…é¢ä¸è¶³")

        return None, None
